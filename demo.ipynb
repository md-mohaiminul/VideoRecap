{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mmiemon/anaconda3/envs/videorecap/lib/python3.8/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/data/mmiemon/anaconda3/envs/videorecap/lib/python3.8/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms._transforms_video as transforms_video\n",
    "from transformers import AutoTokenizer\n",
    "from moviepy.editor import *\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "\n",
    "from src.data.video_transforms import Permute\n",
    "from src.models.video_recap import VideoRecap\n",
    "from src.data.datasets import VideoCaptionDataset, CaptionDataCollator\n",
    "from src.models.timesformer import SpaceTimeTransformer\n",
    "from src.models.openai_model import QuickGELU\n",
    "from src.configs.defaults import defaultConfigs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"assets/example.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"assets/example.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Creating model\n",
      "######USING ATTENTION STYLE:  frozen-in-time\n",
      "=> Loading CLIP (ViT-B/16) weights\n",
      "Loading Video encoder from /data/mmiemon/LaVila/pretrained_models/clip_openai_timesformer_base.baseline.ep_0003.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertLMHeadModel: ['distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'vocab_transform.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'vocab_projector.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.6.output_query.dense.weight', 'encoder.layer.7.output_query.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.output_query.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.6.output_query.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.3.intermediate_query.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.output_query.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.output_query.LayerNorm.bias', 'encoder.layer.8.intermediate_query.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate_query.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.output_query.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.output_query.LayerNorm.bias', 'encoder.layer.6.intermediate_query.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.output_query.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output_query.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.output_query.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.output_query.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.8.output_query.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.output_query.LayerNorm.bias', 'cls.predictions.decoder.weight', 'encoder.layer.0.intermediate_query.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output_query.dense.bias', 'encoder.layer.10.intermediate_query.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.output_query.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.output_query.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.intermediate_query.dense.bias', 'encoder.layer.9.output_query.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.intermediate_query.dense.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.intermediate_query.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.output_query.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.output_query.dense.bias', 'encoder.layer.3.output_query.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.2.output_query.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.intermediate_query.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.output_query.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.1.output_query.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.output_query.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.1.intermediate_query.dense.weight', 'encoder.layer.4.intermediate_query.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate_query.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.output_query.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.output_query.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.output_query.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.6.output_query.LayerNorm.weight', 'encoder.layer.10.intermediate_query.dense.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.10.output_query.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.4.output_query.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.output_query.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.output_query.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.0.intermediate_query.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.output_query.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.output_query.LayerNorm.weight', 'encoder.layer.10.crossattention.self.value.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.11.intermediate_query.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.intermediate_query.dense.weight', 'encoder.layer.1.output_query.LayerNorm.weight', 'encoder.layer.2.output_query.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.11.output_query.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.output_query.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.intermediate_query.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.3.output_query.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.output_query.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.intermediate_query.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.output_query.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.output_query.LayerNorm.weight', 'cls.predictions.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.output_query.dense.weight', 'encoder.layer.9.intermediate_query.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.output_query.dense.weight', 'encoder.layer.7.output_query.LayerNorm.weight', 'encoder.layer.7.intermediate_query.dense.bias', 'encoder.layer.8.intermediate_query.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.output_query.dense.bias', 'encoder.layer.7.intermediate_query.dense.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.output_query.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.intermediate_query.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze the pretrained parts in Bert: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate_query.dense.weight', 'bert.encoder.layer.0.intermediate_query.dense.bias', 'bert.encoder.layer.0.output_query.dense.weight', 'bert.encoder.layer.0.output_query.dense.bias', 'bert.encoder.layer.0.output_query.LayerNorm.weight', 'bert.encoder.layer.0.output_query.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate_query.dense.weight', 'bert.encoder.layer.1.intermediate_query.dense.bias', 'bert.encoder.layer.1.output_query.dense.weight', 'bert.encoder.layer.1.output_query.dense.bias', 'bert.encoder.layer.1.output_query.LayerNorm.weight', 'bert.encoder.layer.1.output_query.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate_query.dense.weight', 'bert.encoder.layer.2.intermediate_query.dense.bias', 'bert.encoder.layer.2.output_query.dense.weight', 'bert.encoder.layer.2.output_query.dense.bias', 'bert.encoder.layer.2.output_query.LayerNorm.weight', 'bert.encoder.layer.2.output_query.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate_query.dense.weight', 'bert.encoder.layer.3.intermediate_query.dense.bias', 'bert.encoder.layer.3.output_query.dense.weight', 'bert.encoder.layer.3.output_query.dense.bias', 'bert.encoder.layer.3.output_query.LayerNorm.weight', 'bert.encoder.layer.3.output_query.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate_query.dense.weight', 'bert.encoder.layer.4.intermediate_query.dense.bias', 'bert.encoder.layer.4.output_query.dense.weight', 'bert.encoder.layer.4.output_query.dense.bias', 'bert.encoder.layer.4.output_query.LayerNorm.weight', 'bert.encoder.layer.4.output_query.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate_query.dense.weight', 'bert.encoder.layer.5.intermediate_query.dense.bias', 'bert.encoder.layer.5.output_query.dense.weight', 'bert.encoder.layer.5.output_query.dense.bias', 'bert.encoder.layer.5.output_query.LayerNorm.weight', 'bert.encoder.layer.5.output_query.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate_query.dense.weight', 'bert.encoder.layer.6.intermediate_query.dense.bias', 'bert.encoder.layer.6.output_query.dense.weight', 'bert.encoder.layer.6.output_query.dense.bias', 'bert.encoder.layer.6.output_query.LayerNorm.weight', 'bert.encoder.layer.6.output_query.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate_query.dense.weight', 'bert.encoder.layer.7.intermediate_query.dense.bias', 'bert.encoder.layer.7.output_query.dense.weight', 'bert.encoder.layer.7.output_query.dense.bias', 'bert.encoder.layer.7.output_query.LayerNorm.weight', 'bert.encoder.layer.7.output_query.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate_query.dense.weight', 'bert.encoder.layer.8.intermediate_query.dense.bias', 'bert.encoder.layer.8.output_query.dense.weight', 'bert.encoder.layer.8.output_query.dense.bias', 'bert.encoder.layer.8.output_query.LayerNorm.weight', 'bert.encoder.layer.8.output_query.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate_query.dense.weight', 'bert.encoder.layer.9.intermediate_query.dense.bias', 'bert.encoder.layer.9.output_query.dense.weight', 'bert.encoder.layer.9.output_query.dense.bias', 'bert.encoder.layer.9.output_query.LayerNorm.weight', 'bert.encoder.layer.9.output_query.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate_query.dense.weight', 'bert.encoder.layer.10.intermediate_query.dense.bias', 'bert.encoder.layer.10.output_query.dense.weight', 'bert.encoder.layer.10.output_query.dense.bias', 'bert.encoder.layer.10.output_query.LayerNorm.weight', 'bert.encoder.layer.10.output_query.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate_query.dense.weight', 'bert.encoder.layer.11.intermediate_query.dense.bias', 'bert.encoder.layer.11.output_query.dense.weight', 'bert.encoder.layer.11.output_query.dense.bias', 'bert.encoder.layer.11.output_query.LayerNorm.weight', 'bert.encoder.layer.11.output_query.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Learn the rest parts in Bert: ['bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias']\n",
      "Freeze the pretrained parts in Bert: 273\n",
      "Learn the rest parts in Bert: 60\n",
      "Freeze the pretrained parts in LM: 100\n",
      "Learn the rest parts in LM: 240\n",
      "=> loaded resume checkpoint 'pretrained_models/videorecap/videorecap_clip.pt' (epoch 5)\n"
     ]
    }
   ],
   "source": [
    "# Create model and tokenizer\n",
    "ckpt_path = 'pretrained_models/videorecap/videorecap_clip.pt'\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "old_args = ckpt['args']\n",
    "old_args.video_feature_type = 'pixel'  \n",
    "old_args.num_video_feat=4                     # number of frames per clip caption\n",
    "crop_size = 224\n",
    "transform = transforms.Compose([\n",
    "        Permute([3, 0, 1, 2]),  # T H W C -> C T H W\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms_video.NormalizeVideo(mean=[108.3272985, 116.7460125, 104.09373615000001], std=[68.5005327, 66.6321579, 70.32316305]),\n",
    "    ])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(old_args.decoder_name)\n",
    "state_dict = OrderedDict()\n",
    "for k, v in ckpt['state_dict'].items():\n",
    "    state_dict[k.replace('module.', '')] = v\n",
    "\n",
    "print(\"=> Creating model\")\n",
    "model = VideoRecap(old_args)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "print(\"=> loaded resume checkpoint '{}' (epoch {})\".format(ckpt_path, ckpt['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video length 708.03 seconds\n",
      "number of captions 178\n",
      "178 23\n"
     ]
    }
   ],
   "source": [
    "# Create dataset from the video\n",
    "video = VideoFileClip('assets/example.mp4')\n",
    "print('Video length', video.duration, 'seconds')\n",
    "\n",
    "video_length = video.duration\n",
    "caption_duration = 4                              # Extract clip caption at each 4 seconds\n",
    "old_args.video_loader_type='moviepy'\n",
    "old_args.chunk_len = -1                           # load from raw video\n",
    "old_args.video_feature_path = 'assets'            # path to the video folder \n",
    "metadata = []  \n",
    "for i in np.arange(0, video_length, caption_duration):\n",
    "    metadata.append(['example', i, min(i + caption_duration, video_length)])    # video name is example.mp4 so assuming video id=example\n",
    "print('number of captions', len(metadata))\n",
    "\n",
    "old_args.metadata = metadata\n",
    "dataset = VideoCaptionDataset(old_args, transform=transform)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False, \n",
    "                                        num_workers=8, pin_memory=True, drop_last=False)\n",
    "print(len(dataset), len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caption decoding function\n",
    "def decode_one(generated_ids, tokenizer):\n",
    "    if tokenizer.eos_token_id == tokenizer.bos_token_id:\n",
    "        if tokenizer.eos_token_id in generated_ids[1:].tolist():\n",
    "            eos_id = generated_ids[1:].tolist().index(tokenizer.eos_token_id) + 1\n",
    "        else:\n",
    "            eos_id = len(generated_ids.tolist()) - 1\n",
    "    elif tokenizer.eos_token_id in generated_ids.tolist():\n",
    "        eos_id = generated_ids.tolist().index(tokenizer.eos_token_id)\n",
    "    else:\n",
    "        eos_id = len(generated_ids.tolist()) - 1\n",
    "    generated_text_str = tokenizer.decode(generated_ids[1:eos_id].tolist())\n",
    "    return generated_text_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 4.0 #C C picks up the nylon of cabbage from the\n",
      "4.0 8.0 #C C puts the cabbage in the bowl\n",
      "8.0 12.0 #C C holds the cabbage with her hands\n",
      "12.0 16.0 #C C puts the nylon on the cabinet\n",
      "16.0 20.0 #C C picks the nylon from the cabinet\n",
      "20.0 24.0 #C C moves her hand towards the counter\n",
      "24.0 28.0 #C C holds the cabbage with both her hands\n",
      "28.0 32.0 #C C closes the fridge.\n",
      "32.0 36.0 #C C picks a nylon from the fridge\n",
      "36.0 40.0 #C C picks the cabbage from the drawer\n",
      "40.0 44.0 #C C puts the nylon in the drawer\n",
      "44.0 48.0 #C C picks up a nylon on the cabinet with her left\n",
      "48.0 52.0 #C C picks the bowl\n",
      "52.0 56.0 #C C cleans the kitchen table with the napkin.\n",
      "56.0 60.0 #C C picks up the bowl from the slab.\n",
      "60.0 64.0 #C C wipes the countertop with the tissue paper\n",
      "64.0 68.0 #C C drops the chopping board on the kitchen slab.\n",
      "68.0 72.0 #C C wipes the countertop with the tissue paper\n",
      "72.0 76.0 #C C picks the bowl from the countertop.\n",
      "76.0 80.0 #C C puts the bowl in the utensil rack\n",
      "80.0 84.0 #C C picks up the pack of flour\n",
      "84.0 88.0 #C C picks a sachet from the pack with her right\n",
      "88.0 92.0 #C C cuts the sachet with the scissors\n",
      "92.0 96.0 #C C picks the scissors from the sink.\n",
      "96.0 100.0 #C C closes the container.\n",
      "100.0 104.0 #C C scoops the groundnut oil with the\n",
      "104.0 108.0 #C C presses the spice on the groundnut\n",
      "108.0 112.0 #C C closes the spice container\n",
      "112.0 116.0 #C C puts the cheese on the pancake\n",
      "116.0 120.0 #C C opens the pack of flour.\n",
      "120.0 124.0 #C C pours the spice into the plate\n",
      "124.0 128.0 #C C puts the knife on the rack\n",
      "128.0 132.0 #C C drops the plate on the plate rack\n",
      "132.0 136.0 #C C pours the flour into the plate\n",
      "136.0 140.0 #C C drops the spoon in the bowl\n",
      "140.0 144.0 #C C picks a spoon from the rack\n",
      "144.0 148.0 #C C opens the cabinet\n",
      "148.0 152.0 #C C turns off the tap.\n",
      "152.0 156.0 #C C picks up the plate from the counter\n",
      "156.0 160.0 #C C drops the scissors on the kitchen slab\n",
      "160.0 164.0 #C C picks a spoon from the rack\n",
      "164.0 168.0 #C C picks a paper towel from the fridge\n",
      "168.0 172.0 #C C picks up a nylon from the top of the cabinet\n",
      "172.0 176.0 #C C picks a paper bag from the shelf\n",
      "176.0 180.0 #C C picks up a plastic container from the shelf.\n",
      "180.0 184.0 #C C picks up the nylon from the top of the nylon\n",
      "184.0 188.0 #C C drops the nylon on the slab.\n",
      "188.0 192.0 #C C removes the paper from the meat\n",
      "192.0 196.0 #C C closes the fridge.\n",
      "196.0 200.0 #C C closes the fridge.\n",
      "200.0 204.0 #C C closes the drawer.\n",
      "204.0 208.0 #C C picks up a spoon from the bowl.\n",
      "208.0 212.0 #C C picks the spoon from the plate with her right\n",
      "212.0 216.0 #C C pours the ingredient into the spoon\n",
      "216.0 220.0 #C C drops the spoon in the plate\n",
      "220.0 224.0 #C C puts the spoon in the plate\n",
      "224.0 228.0 #C C passes the spoon to her right hand\n",
      "228.0 232.0 #C C passes the spring onions to her right hand\n",
      "232.0 236.0 #C C puts the ingredients in the plate\n",
      "236.0 240.0 #C C picks the spoon from the bowl\n",
      "240.0 244.0 #C C puts the spoon in the plate.\n",
      "244.0 248.0 #C C scoops the content of the plate with the\n",
      "248.0 252.0 #C C pours the ingredient into the plate\n",
      "252.0 256.0 #C C spreads the content of the bowl with the spoon\n",
      "256.0 260.0 #C C removes the spring roll from the spoon\n",
      "260.0 264.0 #C C puts the spice in the food\n",
      "264.0 268.0 #C C passes the spring onions to her left\n",
      "268.0 272.0 #C C peels the cheese\n",
      "272.0 276.0 #C C removes the spoon from the spoon\n",
      "276.0 280.0 #C C puts the spring onion in the plate\n",
      "280.0 284.0 #C C puts the cheese on the bread\n",
      "284.0 288.0 #C C scoops the flour with the spoon\n",
      "288.0 292.0 #C C scoops the food with the\n",
      "292.0 296.0 #C C scoops the vegetables with the\n",
      "296.0 300.0 #C C puts the ingredient in the food\n",
      "300.0 304.0 #C C peels the vegetable with her\n",
      "304.0 308.0 #C C puts the ingredients in the plate\n",
      "308.0 312.0 #C C peels the veggie\n",
      "312.0 316.0 #C C puts the food in the bowl\n",
      "316.0 320.0 #C C puts the vegetables in the plate\n",
      "320.0 324.0 #C C scoops the ingredient with the\n",
      "324.0 328.0 #C C pours the ingredient into the\n",
      "328.0 332.0 #C C puts the spoon in the plate\n",
      "332.0 336.0 #C C puts the spoon in the plate\n",
      "336.0 340.0 #C C removes the tofu from the knife\n",
      "340.0 344.0 #C C removes the spring onions\n",
      "344.0 348.0 #C C puts the cheese on the plate\n",
      "348.0 352.0 #C C stirs the food\n",
      "352.0 356.0 #C C scoops the food with the spoon\n",
      "356.0 360.0 #C C scoops the food from the bowl with the spoon\n",
      "360.0 364.0 #C C passes the spoon to her right hand\n",
      "364.0 368.0 #C C removes the spring onions from the stick\n",
      "368.0 372.0 #C C removes the ingredient from the spoon\n",
      "372.0 376.0 #C C breaks the ingredient\n",
      "376.0 380.0 #C C picks the egg from the plate\n",
      "380.0 384.0 #C C stirs the food in the bowl with the spoon\n",
      "Error loading example 708.0 708.03\n",
      "384.0 388.0 #C C scoops the ingredients from the bowl with the\n",
      "388.0 392.0 #C C scoops the content of the bowl with the\n",
      "392.0 396.0 #C C puts the spice on the food\n",
      "396.0 400.0 #C C removes the seeds from the garlic\n",
      "400.0 404.0 #C C removes the seeds from the ingredients\n",
      "404.0 408.0 #C C peels the ingredient\n",
      "408.0 412.0 #C C picks a piece of bread from the plate.\n",
      "412.0 416.0 #C C puts the spoon in the bowl\n",
      "416.0 420.0 #C C scoops the food with the spoon\n",
      "420.0 424.0 #C C puts the spoon in the plate\n",
      "424.0 428.0 #C C removes the spring roll from the plate with her\n",
      "428.0 432.0 #C C removes the seeds from the spring onion\n",
      "432.0 436.0 #C C passes the spring roll to her left hand\n",
      "436.0 440.0 #C C picks the pancake from the plate\n",
      "440.0 444.0 #C C drops the spoon in the bowl\n",
      "444.0 448.0 #C C scoops the food in the bowl with the\n",
      "448.0 452.0 #C C scoops the food in the bowl with the spoon\n",
      "452.0 456.0 #C C holds the spring onion with her hands\n",
      "456.0 460.0 #C C removes the ingredient from the veggie\n",
      "460.0 464.0 #C C removes the seeds from the ingredient\n",
      "464.0 468.0 #C C picks the spring roll from the plate with her right hand\n",
      "468.0 472.0 #C C scoops the food in the plate with the spoon in her right\n",
      "472.0 476.0 #C C scoops the food with the spoon\n",
      "476.0 480.0 #C C puts the food in the bowl\n",
      "480.0 484.0 #C C pours the sauce on the food in the plate\n",
      "484.0 488.0 #C C removes the seeds from the garlic\n",
      "488.0 492.0 #C C removes the vegetables from the chopsticks\n",
      "492.0 496.0 #C C picks the vegetables\n",
      "496.0 500.0 #C C picks up the frying pan from the cooker.\n",
      "500.0 504.0 #C C stirs the content of the container with the spoon in her right\n",
      "504.0 508.0 #C C scoops the food in the bowl with the spoon\n",
      "508.0 512.0 #C C scoops the food with the spoon\n",
      "512.0 516.0 # C C puts the vegetables in the food\n",
      "516.0 520.0 #C C peels the vegetable\n",
      "520.0 524.0 #C C removes the seeds from the stick\n",
      "524.0 528.0 #C C passes the spring roll to her left hand\n",
      "528.0 532.0 #C C stirs the food in the plate with the spoon\n",
      "532.0 536.0 #C C mixes the food\n",
      "536.0 540.0 #C C drops the bowl on the sink.\n",
      "540.0 544.0 #C C rinses her hands with water.\n",
      "544.0 548.0 #C C washes her hands with water from the\n",
      "548.0 552.0 #C C closes the tap.\n",
      "552.0 556.0 #C C puts the pan on the cooker\n",
      "556.0 560.0 #C C picks the bottle of oil from the cooker\n",
      "560.0 564.0 #C C closes the bottle\n",
      "564.0 568.0 #C C puts the oil on the pan\n",
      "568.0 572.0 #C C puts the food in the plate\n",
      "572.0 576.0 #C C puts the pancake in the frying pan\n",
      "576.0 580.0 #C C puts the pancake in the pan\n",
      "580.0 584.0 #C C puts the pancake in the pan\n",
      "584.0 588.0 #C C puts the pancake in the pan\n",
      "588.0 592.0 #C C turns the pancake in the frying pan with the wooden\n",
      "592.0 596.0 #C C turns the pancake in the pan with the chopsticks\n",
      "596.0 600.0 #C C turns the pancake in the pan with the turner\n",
      "600.0 604.0 #C C turns the pieces of cabbage in the pan with the chop\n",
      "604.0 608.0 #C C stirs the food in the pan with the wooden spoon\n",
      "608.0 612.0 #C C turns off the tap.\n",
      "612.0 616.0 #C C picks up the plate from the sink.\n",
      "616.0 620.0 #C C opens the box\n",
      "620.0 624.0 #C C drops the nylon on the counter\n",
      "624.0 628.0 #C C places the bowl on the table\n",
      "628.0 632.0 #C C passes the plate to her left hand\n",
      "632.0 636.0 #C C turns on the gas cooker.\n",
      "636.0 640.0 #C C stirs the food in the pan with the chop\n",
      "640.0 644.0 #C C moves her hand towards the\n",
      "644.0 648.0 #C C closes the drawer.\n",
      "648.0 652.0 #C C closes the drawer\n",
      "652.0 656.0 #C C closes the pot.\n",
      "656.0 660.0 #C C moves her hand towards her\n",
      "660.0 664.0 #C C looks around the kitchen\n",
      "664.0 668.0 #C C looks at the pan\n",
      "668.0 672.0 #C C stares at the pan\n",
      "672.0 676.0 #C C stares at the\n",
      "676.0 680.0 #C C moves her head\n",
      "680.0 684.0 #C C stares at the\n",
      "684.0 688.0 #C C stares at the\n",
      "688.0 692.0 #C C stares at the\n",
      "692.0 696.0 #C C looks at the\n",
      "696.0 700.0 #C C stares at the\n",
      "700.0 704.0 #C C looks at the\n",
      "704.0 708.0 #C C looks at the\n",
      "708.0 708.03 #C C looks around\n"
     ]
    }
   ],
   "source": [
    "captions = {}\n",
    "with torch.no_grad():\n",
    "    for data_iter, samples in enumerate(data_loader):\n",
    "        indices = samples['index']\n",
    "        if hasattr(model, \"vision_model\"):\n",
    "            image = samples[\"video_features\"].permute(0, 2, 1, 3, 4).contiguous().cuda()  # BCTHW -> BTCHW\n",
    "            samples[\"video_features\"] = model.vision_model.forward_features(image, use_checkpoint=old_args.use_checkpoint, cls_at_last=False)  # NLD\n",
    "        \n",
    "        queries = model.map_features(samples)\n",
    "    \n",
    "        if old_args.caption_sample == 'multinomial_sample':\n",
    "            generated_text_ids, ppls = model.generate(\n",
    "                queries,\n",
    "                tokenizer,\n",
    "                do_sample = False,\n",
    "                max_text_length=old_args.max_gen_tokens,\n",
    "                num_return_sequences=old_args.caption_num_return_sequences,\n",
    "            )\n",
    "            \n",
    "        for j in range(generated_text_ids.shape[0]):\n",
    "            sample = dataset.samples[indices[j].item()]\n",
    "            start_sec = sample[1]\n",
    "            for k in range(old_args.caption_num_return_sequences):\n",
    "                jj = j * old_args.caption_num_return_sequences + k\n",
    "                generated_text_str = decode_one(generated_text_ids[jj], tokenizer).strip()\n",
    "                captions[start_sec] = sample + [generated_text_str]\n",
    "                print(sample[1], sample[2], generated_text_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|                            | 16/23 [00:19<00:02,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading example 708.0 708.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 23/23 [00:27<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_features = {}\n",
    "with torch.no_grad():\n",
    "    for data_iter, samples in enumerate(tqdm(data_loader)):\n",
    "        image = samples[\"video_features\"].permute(0, 2, 1, 3, 4).contiguous().cuda()  # BCTHW -> BTCHW\n",
    "        features = model.vision_model.forward_features(image, cls_at_last=True)  # NLD\n",
    "        for j in range(features.shape[0]):\n",
    "            start_sec = dataset.samples[samples['index'][j].item()][1]\n",
    "            all_features[start_sec] = features[j].detach().cpu().numpy()\n",
    "            # print(start_sec, all_features[start_sec].shape)\n",
    "           \n",
    "seconds = list(all_features.keys())\n",
    "seconds.sort()\n",
    "features = []\n",
    "for s in seconds:\n",
    "    features.append(all_features[s])\n",
    "features = np.stack(features)\n",
    "print(features.shape)\n",
    "np.save('assets/example.npy', features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Creating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertLMHeadModel: ['distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'vocab_transform.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'vocab_projector.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.6.output_query.dense.weight', 'encoder.layer.7.output_query.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.output_query.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.6.output_query.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.3.intermediate_query.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.output_query.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.output_query.LayerNorm.bias', 'encoder.layer.8.intermediate_query.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate_query.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.output_query.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.output_query.LayerNorm.bias', 'encoder.layer.6.intermediate_query.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.output_query.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output_query.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.output_query.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.output_query.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.8.output_query.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.output_query.LayerNorm.bias', 'cls.predictions.decoder.weight', 'encoder.layer.0.intermediate_query.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output_query.dense.bias', 'encoder.layer.10.intermediate_query.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.output_query.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.output_query.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.intermediate_query.dense.bias', 'encoder.layer.9.output_query.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.intermediate_query.dense.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.intermediate_query.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.output_query.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.output_query.dense.bias', 'encoder.layer.3.output_query.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.2.output_query.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.intermediate_query.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.output_query.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.1.output_query.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.output_query.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.1.intermediate_query.dense.weight', 'encoder.layer.4.intermediate_query.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate_query.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.output_query.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.output_query.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.output_query.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.6.output_query.LayerNorm.weight', 'encoder.layer.10.intermediate_query.dense.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.10.output_query.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.4.output_query.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.output_query.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.output_query.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.0.intermediate_query.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.output_query.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.output_query.LayerNorm.weight', 'encoder.layer.10.crossattention.self.value.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.11.intermediate_query.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.intermediate_query.dense.weight', 'encoder.layer.1.output_query.LayerNorm.weight', 'encoder.layer.2.output_query.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.11.output_query.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.output_query.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.intermediate_query.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.3.output_query.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.output_query.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.intermediate_query.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.output_query.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.output_query.LayerNorm.weight', 'cls.predictions.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.output_query.dense.weight', 'encoder.layer.9.intermediate_query.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.output_query.dense.weight', 'encoder.layer.7.output_query.LayerNorm.weight', 'encoder.layer.7.intermediate_query.dense.bias', 'encoder.layer.8.intermediate_query.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.output_query.dense.bias', 'encoder.layer.7.intermediate_query.dense.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.output_query.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.intermediate_query.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze the pretrained parts in Bert: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate_query.dense.weight', 'bert.encoder.layer.0.intermediate_query.dense.bias', 'bert.encoder.layer.0.output_query.dense.weight', 'bert.encoder.layer.0.output_query.dense.bias', 'bert.encoder.layer.0.output_query.LayerNorm.weight', 'bert.encoder.layer.0.output_query.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate_query.dense.weight', 'bert.encoder.layer.1.intermediate_query.dense.bias', 'bert.encoder.layer.1.output_query.dense.weight', 'bert.encoder.layer.1.output_query.dense.bias', 'bert.encoder.layer.1.output_query.LayerNorm.weight', 'bert.encoder.layer.1.output_query.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate_query.dense.weight', 'bert.encoder.layer.2.intermediate_query.dense.bias', 'bert.encoder.layer.2.output_query.dense.weight', 'bert.encoder.layer.2.output_query.dense.bias', 'bert.encoder.layer.2.output_query.LayerNorm.weight', 'bert.encoder.layer.2.output_query.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate_query.dense.weight', 'bert.encoder.layer.3.intermediate_query.dense.bias', 'bert.encoder.layer.3.output_query.dense.weight', 'bert.encoder.layer.3.output_query.dense.bias', 'bert.encoder.layer.3.output_query.LayerNorm.weight', 'bert.encoder.layer.3.output_query.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate_query.dense.weight', 'bert.encoder.layer.4.intermediate_query.dense.bias', 'bert.encoder.layer.4.output_query.dense.weight', 'bert.encoder.layer.4.output_query.dense.bias', 'bert.encoder.layer.4.output_query.LayerNorm.weight', 'bert.encoder.layer.4.output_query.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate_query.dense.weight', 'bert.encoder.layer.5.intermediate_query.dense.bias', 'bert.encoder.layer.5.output_query.dense.weight', 'bert.encoder.layer.5.output_query.dense.bias', 'bert.encoder.layer.5.output_query.LayerNorm.weight', 'bert.encoder.layer.5.output_query.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate_query.dense.weight', 'bert.encoder.layer.6.intermediate_query.dense.bias', 'bert.encoder.layer.6.output_query.dense.weight', 'bert.encoder.layer.6.output_query.dense.bias', 'bert.encoder.layer.6.output_query.LayerNorm.weight', 'bert.encoder.layer.6.output_query.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate_query.dense.weight', 'bert.encoder.layer.7.intermediate_query.dense.bias', 'bert.encoder.layer.7.output_query.dense.weight', 'bert.encoder.layer.7.output_query.dense.bias', 'bert.encoder.layer.7.output_query.LayerNorm.weight', 'bert.encoder.layer.7.output_query.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate_query.dense.weight', 'bert.encoder.layer.8.intermediate_query.dense.bias', 'bert.encoder.layer.8.output_query.dense.weight', 'bert.encoder.layer.8.output_query.dense.bias', 'bert.encoder.layer.8.output_query.LayerNorm.weight', 'bert.encoder.layer.8.output_query.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate_query.dense.weight', 'bert.encoder.layer.9.intermediate_query.dense.bias', 'bert.encoder.layer.9.output_query.dense.weight', 'bert.encoder.layer.9.output_query.dense.bias', 'bert.encoder.layer.9.output_query.LayerNorm.weight', 'bert.encoder.layer.9.output_query.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate_query.dense.weight', 'bert.encoder.layer.10.intermediate_query.dense.bias', 'bert.encoder.layer.10.output_query.dense.weight', 'bert.encoder.layer.10.output_query.dense.bias', 'bert.encoder.layer.10.output_query.LayerNorm.weight', 'bert.encoder.layer.10.output_query.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate_query.dense.weight', 'bert.encoder.layer.11.intermediate_query.dense.bias', 'bert.encoder.layer.11.output_query.dense.weight', 'bert.encoder.layer.11.output_query.dense.bias', 'bert.encoder.layer.11.output_query.LayerNorm.weight', 'bert.encoder.layer.11.output_query.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Learn the rest parts in Bert: ['bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias']\n",
      "Freeze the pretrained parts in Bert: 273\n",
      "Learn the rest parts in Bert: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertLMHeadModel: ['distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'vocab_transform.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'vocab_projector.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.6.output_query.dense.weight', 'encoder.layer.7.output_query.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.output_query.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.6.output_query.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.3.intermediate_query.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.output_query.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.output_query.LayerNorm.bias', 'encoder.layer.8.intermediate_query.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate_query.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.output_query.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.output_query.LayerNorm.bias', 'encoder.layer.6.intermediate_query.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.output_query.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output_query.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.output_query.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.output_query.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.8.output_query.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.output_query.LayerNorm.bias', 'cls.predictions.decoder.weight', 'encoder.layer.0.intermediate_query.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output_query.dense.bias', 'encoder.layer.10.intermediate_query.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.output_query.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.output_query.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.intermediate_query.dense.bias', 'encoder.layer.9.output_query.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.intermediate_query.dense.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.intermediate_query.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.output_query.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.output_query.dense.bias', 'encoder.layer.3.output_query.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.2.output_query.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.intermediate_query.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.output_query.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.1.output_query.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.output_query.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.1.intermediate_query.dense.weight', 'encoder.layer.4.intermediate_query.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate_query.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.output_query.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.output_query.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.output_query.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.6.output_query.LayerNorm.weight', 'encoder.layer.10.intermediate_query.dense.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.10.output_query.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.4.output_query.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.output_query.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.output_query.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.0.intermediate_query.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.output_query.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.output_query.LayerNorm.weight', 'encoder.layer.10.crossattention.self.value.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.11.intermediate_query.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.intermediate_query.dense.weight', 'encoder.layer.1.output_query.LayerNorm.weight', 'encoder.layer.2.output_query.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.11.output_query.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.output_query.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.intermediate_query.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.3.output_query.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.output_query.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.intermediate_query.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.output_query.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.output_query.LayerNorm.weight', 'cls.predictions.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.output_query.dense.weight', 'encoder.layer.9.intermediate_query.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.output_query.dense.weight', 'encoder.layer.7.output_query.LayerNorm.weight', 'encoder.layer.7.intermediate_query.dense.bias', 'encoder.layer.8.intermediate_query.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.output_query.dense.bias', 'encoder.layer.7.intermediate_query.dense.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.output_query.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.intermediate_query.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze the pretrained parts in Bert: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate_query.dense.weight', 'bert.encoder.layer.0.intermediate_query.dense.bias', 'bert.encoder.layer.0.output_query.dense.weight', 'bert.encoder.layer.0.output_query.dense.bias', 'bert.encoder.layer.0.output_query.LayerNorm.weight', 'bert.encoder.layer.0.output_query.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate_query.dense.weight', 'bert.encoder.layer.1.intermediate_query.dense.bias', 'bert.encoder.layer.1.output_query.dense.weight', 'bert.encoder.layer.1.output_query.dense.bias', 'bert.encoder.layer.1.output_query.LayerNorm.weight', 'bert.encoder.layer.1.output_query.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate_query.dense.weight', 'bert.encoder.layer.2.intermediate_query.dense.bias', 'bert.encoder.layer.2.output_query.dense.weight', 'bert.encoder.layer.2.output_query.dense.bias', 'bert.encoder.layer.2.output_query.LayerNorm.weight', 'bert.encoder.layer.2.output_query.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate_query.dense.weight', 'bert.encoder.layer.3.intermediate_query.dense.bias', 'bert.encoder.layer.3.output_query.dense.weight', 'bert.encoder.layer.3.output_query.dense.bias', 'bert.encoder.layer.3.output_query.LayerNorm.weight', 'bert.encoder.layer.3.output_query.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate_query.dense.weight', 'bert.encoder.layer.4.intermediate_query.dense.bias', 'bert.encoder.layer.4.output_query.dense.weight', 'bert.encoder.layer.4.output_query.dense.bias', 'bert.encoder.layer.4.output_query.LayerNorm.weight', 'bert.encoder.layer.4.output_query.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate_query.dense.weight', 'bert.encoder.layer.5.intermediate_query.dense.bias', 'bert.encoder.layer.5.output_query.dense.weight', 'bert.encoder.layer.5.output_query.dense.bias', 'bert.encoder.layer.5.output_query.LayerNorm.weight', 'bert.encoder.layer.5.output_query.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate_query.dense.weight', 'bert.encoder.layer.6.intermediate_query.dense.bias', 'bert.encoder.layer.6.output_query.dense.weight', 'bert.encoder.layer.6.output_query.dense.bias', 'bert.encoder.layer.6.output_query.LayerNorm.weight', 'bert.encoder.layer.6.output_query.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate_query.dense.weight', 'bert.encoder.layer.7.intermediate_query.dense.bias', 'bert.encoder.layer.7.output_query.dense.weight', 'bert.encoder.layer.7.output_query.dense.bias', 'bert.encoder.layer.7.output_query.LayerNorm.weight', 'bert.encoder.layer.7.output_query.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate_query.dense.weight', 'bert.encoder.layer.8.intermediate_query.dense.bias', 'bert.encoder.layer.8.output_query.dense.weight', 'bert.encoder.layer.8.output_query.dense.bias', 'bert.encoder.layer.8.output_query.LayerNorm.weight', 'bert.encoder.layer.8.output_query.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate_query.dense.weight', 'bert.encoder.layer.9.intermediate_query.dense.bias', 'bert.encoder.layer.9.output_query.dense.weight', 'bert.encoder.layer.9.output_query.dense.bias', 'bert.encoder.layer.9.output_query.LayerNorm.weight', 'bert.encoder.layer.9.output_query.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate_query.dense.weight', 'bert.encoder.layer.10.intermediate_query.dense.bias', 'bert.encoder.layer.10.output_query.dense.weight', 'bert.encoder.layer.10.output_query.dense.bias', 'bert.encoder.layer.10.output_query.LayerNorm.weight', 'bert.encoder.layer.10.output_query.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate_query.dense.weight', 'bert.encoder.layer.11.intermediate_query.dense.bias', 'bert.encoder.layer.11.output_query.dense.weight', 'bert.encoder.layer.11.output_query.dense.bias', 'bert.encoder.layer.11.output_query.LayerNorm.weight', 'bert.encoder.layer.11.output_query.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Learn the rest parts in Bert: ['bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias']\n",
      "Freeze the pretrained parts in Bert: 273\n",
      "Learn the rest parts in Bert: 60\n",
      "Freeze the pretrained parts in LM: 100\n",
      "Learn the rest parts in LM: 240\n",
      "=> loaded resume checkpoint 'pretrained_models/videorecap/videorecap_segment.pt' (epoch 15)\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = 'pretrained_models/videorecap/videorecap_segment.pt'\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "old_args = ckpt['args']\n",
    "old_args.video_feature_type = 'cls'\n",
    "old_args.video_feature_path = 'assets'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(old_args.decoder_name)\n",
    "collator = CaptionDataCollator(tokenizer, max_gen_tokens = old_args.max_gen_tokens,\n",
    "                                add_bos = True, add_eos = True, pad_token_id = 0)\n",
    "state_dict = OrderedDict()\n",
    "for k, v in ckpt['state_dict'].items():\n",
    "    state_dict[k.replace('module.', '')] = v\n",
    "    \n",
    "print(\"=> Creating model\")\n",
    "model = VideoRecap(old_args)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "print(\"=> loaded resume checkpoint '{}' (epoch {})\".format(ckpt_path, ckpt['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video length 708.03 seconds\n",
      "Number of segments 4\n",
      "4 1\n"
     ]
    }
   ],
   "source": [
    "video = VideoFileClip('assets/example.mp4')\n",
    "print('Video length', video.duration, 'seconds')\n",
    "\n",
    "old_args.video_feature_path = 'assets' \n",
    "video_length = video.duration\n",
    "segment_step = 180        # Extract one segment description at each 180 sconds\n",
    "metadata = []\n",
    "for i in np.arange(0, video_length, segment_step):\n",
    "    dd = {}\n",
    "    dd['vid'] = 'example'\n",
    "    dd['start_sec'] = i\n",
    "    dd['end_sec'] = min(i+segment_step, video_length)\n",
    "    dd['captions_pred'] = []\n",
    "    for s, c in captions.items():\n",
    "        if c[1]>=dd['start_sec'] and c[2]<=dd['end_sec']:\n",
    "            dd['captions_pred'].append(c)\n",
    "    metadata.append(dd)\n",
    "print('Number of segments', len(metadata))\n",
    "    \n",
    "old_args.metadata = metadata\n",
    "dataset = VideoCaptionDataset(old_args, transform=None)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=False, \n",
    "                    collate_fn=collator, num_workers=4, pin_memory=True, drop_last=False)\n",
    "print(len(dataset), len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 180.0 C was in a kitchen. C washed a plate in a wash basin. C arranged the plates in a plate rack\n",
      "180.0 360.0 C was in a kitchen. C mixed a mixture of cheese and flour. C poured the mixture into a plate.\n",
      "360.0 540.0 C was in a kitchen. C poured oil into a plate. C poured oil into a plate.\n",
      "540.0 708.03 C was in a kitchen. C fried fish in a frying pan. C wiped her hands with a tissue paper.\n"
     ]
    }
   ],
   "source": [
    "segment_descriptions = {}\n",
    "with torch.no_grad():\n",
    "    for data_iter, samples in enumerate(data_loader):\n",
    "        indices = samples['indices']\n",
    "        if hasattr(model, \"vision_model\"):\n",
    "            image = samples[\"video_features\"].permute(0, 2, 1, 3, 4).contiguous().cuda()  # BCTHW -> BTCHW\n",
    "            samples[\"video_features\"] = model.vision_model.forward_features(image, use_checkpoint=old_args.use_checkpoint, cls_at_last=False)  # NLD\n",
    "        \n",
    "        queries = model.map_features(samples)\n",
    "    \n",
    "        if old_args.caption_sample == 'multinomial_sample':\n",
    "            generated_text_ids, ppls = model.generate(\n",
    "                queries,\n",
    "                tokenizer,\n",
    "                do_sample = False,\n",
    "                max_text_length=old_args.max_gen_tokens,\n",
    "                num_return_sequences=old_args.caption_num_return_sequences,\n",
    "            )\n",
    "            \n",
    "        for j in range(generated_text_ids.shape[0]):\n",
    "            sample = dataset.samples[indices[j].item()]\n",
    "            start_sec = sample['start_sec']\n",
    "            for k in range(old_args.caption_num_return_sequences):\n",
    "                jj = j * old_args.caption_num_return_sequences + k\n",
    "                generated_text_str = decode_one(generated_text_ids[jj], tokenizer).strip()\n",
    "                segment_descriptions[start_sec] = generated_text_str\n",
    "                print(sample['start_sec'], sample['end_sec'], generated_text_str)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Creating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertLMHeadModel: ['distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'vocab_transform.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'vocab_projector.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.6.output_query.dense.weight', 'encoder.layer.7.output_query.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.output_query.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.6.output_query.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.3.intermediate_query.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.output_query.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.output_query.LayerNorm.bias', 'encoder.layer.8.intermediate_query.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate_query.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.output_query.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.output_query.LayerNorm.bias', 'encoder.layer.6.intermediate_query.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.output_query.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output_query.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.output_query.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.output_query.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.8.output_query.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.output_query.LayerNorm.bias', 'cls.predictions.decoder.weight', 'encoder.layer.0.intermediate_query.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output_query.dense.bias', 'encoder.layer.10.intermediate_query.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.output_query.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.output_query.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.intermediate_query.dense.bias', 'encoder.layer.9.output_query.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.intermediate_query.dense.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.intermediate_query.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.output_query.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.output_query.dense.bias', 'encoder.layer.3.output_query.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.2.output_query.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.intermediate_query.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.output_query.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.1.output_query.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.output_query.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.1.intermediate_query.dense.weight', 'encoder.layer.4.intermediate_query.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate_query.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.output_query.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.output_query.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.output_query.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.6.output_query.LayerNorm.weight', 'encoder.layer.10.intermediate_query.dense.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.10.output_query.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.4.output_query.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.output_query.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.output_query.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.0.intermediate_query.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.output_query.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.output_query.LayerNorm.weight', 'encoder.layer.10.crossattention.self.value.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.11.intermediate_query.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.intermediate_query.dense.weight', 'encoder.layer.1.output_query.LayerNorm.weight', 'encoder.layer.2.output_query.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.11.output_query.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.output_query.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.intermediate_query.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.3.output_query.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.output_query.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.intermediate_query.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.output_query.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.output_query.LayerNorm.weight', 'cls.predictions.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.output_query.dense.weight', 'encoder.layer.9.intermediate_query.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.output_query.dense.weight', 'encoder.layer.7.output_query.LayerNorm.weight', 'encoder.layer.7.intermediate_query.dense.bias', 'encoder.layer.8.intermediate_query.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.output_query.dense.bias', 'encoder.layer.7.intermediate_query.dense.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.output_query.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.intermediate_query.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze the pretrained parts in Bert: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate_query.dense.weight', 'bert.encoder.layer.0.intermediate_query.dense.bias', 'bert.encoder.layer.0.output_query.dense.weight', 'bert.encoder.layer.0.output_query.dense.bias', 'bert.encoder.layer.0.output_query.LayerNorm.weight', 'bert.encoder.layer.0.output_query.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate_query.dense.weight', 'bert.encoder.layer.1.intermediate_query.dense.bias', 'bert.encoder.layer.1.output_query.dense.weight', 'bert.encoder.layer.1.output_query.dense.bias', 'bert.encoder.layer.1.output_query.LayerNorm.weight', 'bert.encoder.layer.1.output_query.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate_query.dense.weight', 'bert.encoder.layer.2.intermediate_query.dense.bias', 'bert.encoder.layer.2.output_query.dense.weight', 'bert.encoder.layer.2.output_query.dense.bias', 'bert.encoder.layer.2.output_query.LayerNorm.weight', 'bert.encoder.layer.2.output_query.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate_query.dense.weight', 'bert.encoder.layer.3.intermediate_query.dense.bias', 'bert.encoder.layer.3.output_query.dense.weight', 'bert.encoder.layer.3.output_query.dense.bias', 'bert.encoder.layer.3.output_query.LayerNorm.weight', 'bert.encoder.layer.3.output_query.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate_query.dense.weight', 'bert.encoder.layer.4.intermediate_query.dense.bias', 'bert.encoder.layer.4.output_query.dense.weight', 'bert.encoder.layer.4.output_query.dense.bias', 'bert.encoder.layer.4.output_query.LayerNorm.weight', 'bert.encoder.layer.4.output_query.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate_query.dense.weight', 'bert.encoder.layer.5.intermediate_query.dense.bias', 'bert.encoder.layer.5.output_query.dense.weight', 'bert.encoder.layer.5.output_query.dense.bias', 'bert.encoder.layer.5.output_query.LayerNorm.weight', 'bert.encoder.layer.5.output_query.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate_query.dense.weight', 'bert.encoder.layer.6.intermediate_query.dense.bias', 'bert.encoder.layer.6.output_query.dense.weight', 'bert.encoder.layer.6.output_query.dense.bias', 'bert.encoder.layer.6.output_query.LayerNorm.weight', 'bert.encoder.layer.6.output_query.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate_query.dense.weight', 'bert.encoder.layer.7.intermediate_query.dense.bias', 'bert.encoder.layer.7.output_query.dense.weight', 'bert.encoder.layer.7.output_query.dense.bias', 'bert.encoder.layer.7.output_query.LayerNorm.weight', 'bert.encoder.layer.7.output_query.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate_query.dense.weight', 'bert.encoder.layer.8.intermediate_query.dense.bias', 'bert.encoder.layer.8.output_query.dense.weight', 'bert.encoder.layer.8.output_query.dense.bias', 'bert.encoder.layer.8.output_query.LayerNorm.weight', 'bert.encoder.layer.8.output_query.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate_query.dense.weight', 'bert.encoder.layer.9.intermediate_query.dense.bias', 'bert.encoder.layer.9.output_query.dense.weight', 'bert.encoder.layer.9.output_query.dense.bias', 'bert.encoder.layer.9.output_query.LayerNorm.weight', 'bert.encoder.layer.9.output_query.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate_query.dense.weight', 'bert.encoder.layer.10.intermediate_query.dense.bias', 'bert.encoder.layer.10.output_query.dense.weight', 'bert.encoder.layer.10.output_query.dense.bias', 'bert.encoder.layer.10.output_query.LayerNorm.weight', 'bert.encoder.layer.10.output_query.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate_query.dense.weight', 'bert.encoder.layer.11.intermediate_query.dense.bias', 'bert.encoder.layer.11.output_query.dense.weight', 'bert.encoder.layer.11.output_query.dense.bias', 'bert.encoder.layer.11.output_query.LayerNorm.weight', 'bert.encoder.layer.11.output_query.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Learn the rest parts in Bert: ['bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias']\n",
      "Freeze the pretrained parts in Bert: 273\n",
      "Learn the rest parts in Bert: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertLMHeadModel: ['distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'vocab_transform.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'vocab_projector.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.6.output_query.dense.weight', 'encoder.layer.7.output_query.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.output_query.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.6.output_query.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.3.intermediate_query.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.output_query.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.output_query.LayerNorm.bias', 'encoder.layer.8.intermediate_query.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate_query.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.output_query.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.output_query.LayerNorm.bias', 'encoder.layer.6.intermediate_query.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.output_query.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output_query.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.output_query.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.output_query.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.8.output_query.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.output_query.LayerNorm.bias', 'cls.predictions.decoder.weight', 'encoder.layer.0.intermediate_query.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output_query.dense.bias', 'encoder.layer.10.intermediate_query.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.output_query.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.output_query.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.intermediate_query.dense.bias', 'encoder.layer.9.output_query.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.intermediate_query.dense.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.intermediate_query.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.output_query.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.output_query.dense.bias', 'encoder.layer.3.output_query.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.2.output_query.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.intermediate_query.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.output_query.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.1.output_query.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.output_query.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.1.intermediate_query.dense.weight', 'encoder.layer.4.intermediate_query.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate_query.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.output_query.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.output_query.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.output_query.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.6.output_query.LayerNorm.weight', 'encoder.layer.10.intermediate_query.dense.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.10.output_query.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.4.output_query.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.output_query.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.output_query.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.0.intermediate_query.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.output_query.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.output_query.LayerNorm.weight', 'encoder.layer.10.crossattention.self.value.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.11.intermediate_query.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.intermediate_query.dense.weight', 'encoder.layer.1.output_query.LayerNorm.weight', 'encoder.layer.2.output_query.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.11.output_query.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.output_query.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.intermediate_query.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.3.output_query.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.output_query.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.intermediate_query.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.output_query.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.output_query.LayerNorm.weight', 'cls.predictions.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.output_query.dense.weight', 'encoder.layer.9.intermediate_query.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.output_query.dense.weight', 'encoder.layer.7.output_query.LayerNorm.weight', 'encoder.layer.7.intermediate_query.dense.bias', 'encoder.layer.8.intermediate_query.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.output_query.dense.bias', 'encoder.layer.7.intermediate_query.dense.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.output_query.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.intermediate_query.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze the pretrained parts in Bert: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate_query.dense.weight', 'bert.encoder.layer.0.intermediate_query.dense.bias', 'bert.encoder.layer.0.output_query.dense.weight', 'bert.encoder.layer.0.output_query.dense.bias', 'bert.encoder.layer.0.output_query.LayerNorm.weight', 'bert.encoder.layer.0.output_query.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate_query.dense.weight', 'bert.encoder.layer.1.intermediate_query.dense.bias', 'bert.encoder.layer.1.output_query.dense.weight', 'bert.encoder.layer.1.output_query.dense.bias', 'bert.encoder.layer.1.output_query.LayerNorm.weight', 'bert.encoder.layer.1.output_query.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate_query.dense.weight', 'bert.encoder.layer.2.intermediate_query.dense.bias', 'bert.encoder.layer.2.output_query.dense.weight', 'bert.encoder.layer.2.output_query.dense.bias', 'bert.encoder.layer.2.output_query.LayerNorm.weight', 'bert.encoder.layer.2.output_query.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate_query.dense.weight', 'bert.encoder.layer.3.intermediate_query.dense.bias', 'bert.encoder.layer.3.output_query.dense.weight', 'bert.encoder.layer.3.output_query.dense.bias', 'bert.encoder.layer.3.output_query.LayerNorm.weight', 'bert.encoder.layer.3.output_query.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate_query.dense.weight', 'bert.encoder.layer.4.intermediate_query.dense.bias', 'bert.encoder.layer.4.output_query.dense.weight', 'bert.encoder.layer.4.output_query.dense.bias', 'bert.encoder.layer.4.output_query.LayerNorm.weight', 'bert.encoder.layer.4.output_query.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate_query.dense.weight', 'bert.encoder.layer.5.intermediate_query.dense.bias', 'bert.encoder.layer.5.output_query.dense.weight', 'bert.encoder.layer.5.output_query.dense.bias', 'bert.encoder.layer.5.output_query.LayerNorm.weight', 'bert.encoder.layer.5.output_query.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate_query.dense.weight', 'bert.encoder.layer.6.intermediate_query.dense.bias', 'bert.encoder.layer.6.output_query.dense.weight', 'bert.encoder.layer.6.output_query.dense.bias', 'bert.encoder.layer.6.output_query.LayerNorm.weight', 'bert.encoder.layer.6.output_query.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate_query.dense.weight', 'bert.encoder.layer.7.intermediate_query.dense.bias', 'bert.encoder.layer.7.output_query.dense.weight', 'bert.encoder.layer.7.output_query.dense.bias', 'bert.encoder.layer.7.output_query.LayerNorm.weight', 'bert.encoder.layer.7.output_query.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate_query.dense.weight', 'bert.encoder.layer.8.intermediate_query.dense.bias', 'bert.encoder.layer.8.output_query.dense.weight', 'bert.encoder.layer.8.output_query.dense.bias', 'bert.encoder.layer.8.output_query.LayerNorm.weight', 'bert.encoder.layer.8.output_query.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate_query.dense.weight', 'bert.encoder.layer.9.intermediate_query.dense.bias', 'bert.encoder.layer.9.output_query.dense.weight', 'bert.encoder.layer.9.output_query.dense.bias', 'bert.encoder.layer.9.output_query.LayerNorm.weight', 'bert.encoder.layer.9.output_query.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate_query.dense.weight', 'bert.encoder.layer.10.intermediate_query.dense.bias', 'bert.encoder.layer.10.output_query.dense.weight', 'bert.encoder.layer.10.output_query.dense.bias', 'bert.encoder.layer.10.output_query.LayerNorm.weight', 'bert.encoder.layer.10.output_query.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate_query.dense.weight', 'bert.encoder.layer.11.intermediate_query.dense.bias', 'bert.encoder.layer.11.output_query.dense.weight', 'bert.encoder.layer.11.output_query.dense.bias', 'bert.encoder.layer.11.output_query.LayerNorm.weight', 'bert.encoder.layer.11.output_query.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Learn the rest parts in Bert: ['bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias']\n",
      "Freeze the pretrained parts in Bert: 273\n",
      "Learn the rest parts in Bert: 60\n",
      "Freeze the pretrained parts in LM: 100\n",
      "Learn the rest parts in LM: 240\n",
      "=> loaded resume checkpoint 'pretrained_models/videorecap/videorecap_video.pt' (epoch 25)\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = 'pretrained_models/videorecap/videorecap_video.pt'\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "old_args = ckpt['args']\n",
    "old_args.video_feature_type = 'cls'\n",
    "old_args.video_feature_path = 'assets'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(old_args.decoder_name)\n",
    "collator = CaptionDataCollator(tokenizer, max_gen_tokens = old_args.max_gen_tokens,\n",
    "                                add_bos = True, add_eos = True, pad_token_id = 0)\n",
    "state_dict = OrderedDict()\n",
    "for k, v in ckpt['state_dict'].items():\n",
    "    state_dict[k.replace('module.', '')] = v\n",
    "    \n",
    "print(\"=> Creating model\")\n",
    "model = VideoRecap(old_args)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "print(\"=> loaded resume checkpoint '{}' (epoch {})\".format(ckpt_path, ckpt['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video length 708.03 seconds\n",
      "Number of segments 1\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "video = VideoFileClip('assets/example.mp4')\n",
    "print('Video length', video.duration, 'seconds')\n",
    "\n",
    "old_args.video_feature_path = 'assets' \n",
    "video_length = video.duration\n",
    "metadata = []\n",
    "dd = {}\n",
    "dd['vid'] = 'example'\n",
    "dd['start_sec'] = 0\n",
    "dd['end_sec'] = video.duration\n",
    "dd['segment_descriptions_pred'] = []\n",
    "for s, c in segment_descriptions.items():\n",
    "    dd['segment_descriptions_pred'].append(c)\n",
    "metadata.append(dd)\n",
    "print('Number of segments', len(metadata))\n",
    "    \n",
    "old_args.metadata = metadata\n",
    "dataset = VideoCaptionDataset(old_args, transform=None)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, \n",
    "                    collate_fn=collator, num_workers=1, pin_memory=True, drop_last=False)\n",
    "print(len(dataset), len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a kitchen, C prepared a meal. C cut vegetables into a plate, and cooked the meal\n"
     ]
    }
   ],
   "source": [
    "video_summary = {}\n",
    "with torch.no_grad():\n",
    "    for data_iter, samples in enumerate(data_loader):\n",
    "        indices = samples['indices']\n",
    "        if hasattr(model, \"vision_model\"):\n",
    "            image = samples[\"video_features\"].permute(0, 2, 1, 3, 4).contiguous().cuda()  # BCTHW -> BTCHW\n",
    "            samples[\"video_features\"] = model.vision_model.forward_features(image, use_checkpoint=old_args.use_checkpoint, cls_at_last=False)  # NLD\n",
    "        \n",
    "        queries = model.map_features(samples)\n",
    "    \n",
    "        if old_args.caption_sample == 'multinomial_sample':\n",
    "            generated_text_ids, ppls = model.generate(\n",
    "                queries,\n",
    "                tokenizer,\n",
    "                do_sample = False,\n",
    "                max_text_length=old_args.max_gen_tokens,\n",
    "                num_return_sequences=old_args.caption_num_return_sequences,\n",
    "            )\n",
    "            \n",
    "        for j in range(generated_text_ids.shape[0]):\n",
    "            sample = dataset.samples[indices[j].item()]\n",
    "            start_sec = sample['start_sec']\n",
    "            for k in range(old_args.caption_num_return_sequences):\n",
    "                jj = j * old_args.caption_num_return_sequences + k\n",
    "                generated_text_str = decode_one(generated_text_ids[jj], tokenizer).strip()\n",
    "                video_summary[start_sec] = generated_text_str\n",
    "                print(generated_text_str)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
